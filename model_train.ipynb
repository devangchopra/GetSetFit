{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception = InceptionV3(\n",
    "        weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "for layer in inception.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "x_layer = inception.output\n",
    "x_layer = Flatten()(x_layer)\n",
    "x_layer = Dense(1024, activation='relu')(x_layer)\n",
    "x_layer = Dropout(0.3)(x_layer)\n",
    "\n",
    "predictions = Dense(7, activation='softmax')(x_layer)\n",
    "\n",
    "model = Model(inputs=inception.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(lr=0.0001), \n",
    "              loss = 'sparse_categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# model.compile(optimizer=Adam(lr=0.001),\n",
    "#                       loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2358 images belonging to 7 classes.\n",
      "Found 479 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------add paths\n",
    "train_dir = \"../data/train/\"\n",
    "validation_dir = \"../data/test/\"\n",
    "\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary', \n",
    "                                                    target_size = (224, 224))     \n",
    "\n",
    "\n",
    "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
    "                                                          batch_size  = 20,\n",
    "                                                          class_mode  = 'binary', \n",
    "                                                          target_size = (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 00001: saving model to ../checkpoint/cp.ckpt\n",
      "100/100 - 210s - loss: 1.7181 - accuracy: 0.6982 - val_loss: 0.3729 - val_accuracy: 0.8768\n",
      "Epoch 2/15\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 00002: saving model to ../checkpoint/cp.ckpt\n",
      "100/100 - 225s - loss: 0.5312 - accuracy: 0.8098 - val_loss: 0.3820 - val_accuracy: 0.8706\n",
      "Epoch 3/15\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 00003: saving model to ../checkpoint/cp.ckpt\n",
      "100/100 - 222s - loss: 0.4132 - accuracy: 0.8549 - val_loss: 0.4838 - val_accuracy: 0.8476\n",
      "Epoch 4/15\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 00004: saving model to ../checkpoint/cp.ckpt\n",
      "100/100 - 231s - loss: 0.4208 - accuracy: 0.8554 - val_loss: 0.3343 - val_accuracy: 0.9040\n",
      "Epoch 5/15\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 00005: saving model to ../checkpoint/cp.ckpt\n",
      "100/100 - 252s - loss: 0.3586 - accuracy: 0.8714 - val_loss: 0.3715 - val_accuracy: 0.9061\n",
      "Epoch 6/15\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 00006: saving model to ../checkpoint/cp.ckpt\n",
      "100/100 - 232s - loss: 0.3675 - accuracy: 0.8695 - val_loss: 0.3934 - val_accuracy: 0.8810\n",
      "Epoch 7/15\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 00007: saving model to ../checkpoint/cp.ckpt\n",
      "100/100 - 234s - loss: 0.3319 - accuracy: 0.8804 - val_loss: 0.4066 - val_accuracy: 0.8852\n",
      "Epoch 8/15\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 00008: saving model to ../checkpoint/cp.ckpt\n",
      "100/100 - 237s - loss: 0.3628 - accuracy: 0.8784 - val_loss: 0.3593 - val_accuracy: 0.8914\n",
      "Epoch 9/15\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 00009: saving model to ../checkpoint/cp.ckpt\n",
      "100/100 - 232s - loss: 0.3406 - accuracy: 0.8889 - val_loss: 0.3187 - val_accuracy: 0.9040\n",
      "Epoch 10/15\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 00010: saving model to ../checkpoint/cp.ckpt\n",
      "100/100 - 233s - loss: 0.3000 - accuracy: 0.8954 - val_loss: 0.3874 - val_accuracy: 0.8852\n",
      "Epoch 11/15\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 00011: saving model to ../checkpoint/cp.ckpt\n",
      "100/100 - 231s - loss: 0.2850 - accuracy: 0.8965 - val_loss: 0.3111 - val_accuracy: 0.9061\n",
      "Epoch 12/15\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 00012: saving model to ../checkpoint/cp.ckpt\n",
      "100/100 - 241s - loss: 0.2709 - accuracy: 0.9035 - val_loss: 0.3094 - val_accuracy: 0.9102\n",
      "Epoch 13/15\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 00013: saving model to ../checkpoint/cp.ckpt\n",
      "100/100 - 240s - loss: 0.2724 - accuracy: 0.9079 - val_loss: 0.3242 - val_accuracy: 0.9019\n",
      "Epoch 14/15\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 00014: saving model to ../checkpoint/cp.ckpt\n",
      "100/100 - 233s - loss: 0.2607 - accuracy: 0.9114 - val_loss: 0.3229 - val_accuracy: 0.9061\n",
      "Epoch 15/15\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 00015: saving model to ../checkpoint/cp.ckpt\n",
      "100/100 - 238s - loss: 0.2757 - accuracy: 0.9069 - val_loss: 0.3435 - val_accuracy: 0.9102\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path=\"../checkpoint/cp.ckpt\"\n",
    "checkpoint_dir=os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback=tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                              save_weights_only=True,\n",
    "                                              verbose=1)\n",
    "\n",
    "history=model.fit_generator(train_generator,\n",
    "                            steps_per_epoch=100,\n",
    "                            epochs=15,\n",
    "                            validation_data =validation_generator,\n",
    "                            validation_steps=50,\n",
    "                            verbose=2,\n",
    "                           callbacks=[cp_callback])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
